{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2080 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PRIVATE = 'input/test_private_expanded.csv'\n",
    "TEST_DATA_PUBLIC = 'input/test_public_expanded.csv'\n",
    "\n",
    "# TODO: add also train data analysis for comparison\n",
    "\n",
    "TEST_DATA = 'input/test_private_expanded.csv'\n",
    "\n",
    "test = pd.read_csv(TEST_DATA, index_col='id')\n",
    "\n",
    "test_private_df = pd.read_csv(TEST_DATA_PRIVATE, index_col='id')\n",
    "test_public_df = pd.read_csv(TEST_DATA_PUBLIC, index_col='id')\n",
    "test_combined_df = pd.concat([test_private_df, test_public_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 220\n",
    "batch_size = 512\n",
    "seed = 1029\n",
    "EMBEDDING_FASTTEXT = './input/crawl-300d-2M.vec'\n",
    "max_features = 100000\n",
    "embed_size = 300\n",
    "\n",
    "ps = PorterStemmer()\n",
    "lc = LancasterStemmer()\n",
    "sb = SnowballStemmer('english')\n",
    "\n",
    "# preprocessing\n",
    "misspell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\n",
    "                 \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
    "                 \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                 \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
    "                 \"i'd\": \"I had\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"isn't\": \"is not\",\n",
    "                 \"it's\": \"it is\", \"it'll\": \"it will\", \"i've\": \"I have\", \"let's\": \"let us\",\n",
    "                 \"mightn't\": \"might not\", \"mustn't\": \"must not\", \"shan't\": \"shall not\",\n",
    "                 \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\",\n",
    "                 \"shouldn't\": \"should not\", \"that's\": \"that is\", \"there's\": \"there is\",\n",
    "                 \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\",\n",
    "                 \"they've\": \"they have\", \"we'd\": \"we would\", \"we're\": \"we are\",\n",
    "                 \"weren't\": \"were not\", \"we've\": \"we have\", \"what'll\": \"what will\",\n",
    "                 \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "                 \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
    "                 \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                 \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
    "                 \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
    "                 \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\": \" will\", \"tryin'\": \"trying\"}\n",
    "\n",
    "\n",
    "def _get_misspell(misspell_dict):\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n",
    "    return misspell_dict, misspell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    misspellings, misspellings_re = _get_misspell(misspell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return misspellings[match.group(0)]\n",
    "\n",
    "    return misspellings_re.sub(replace, text)\n",
    "    \n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']',\n",
    "          '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '_', '{', '}', '©', '^',\n",
    "          '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
    "          '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶',\n",
    "          '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼',\n",
    "          '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "          'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪',\n",
    "          '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts + list(string.punctuation):\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    return re.sub(r'\\d+', ' ', x)\n",
    "\n",
    "# load dataframe\n",
    "def load_and_prec(df):\n",
    "    test = df\n",
    "    # lower\n",
    "    test['comment_text'] = test['comment_text'].str.lower()\n",
    "\n",
    "    # clean misspellings\n",
    "    test['comment_text'] = test['comment_text'].apply(replace_typical_misspell)\n",
    "\n",
    "    # clean the text\n",
    "    test['comment_text'] = test['comment_text'].apply(clean_text)\n",
    "\n",
    "    # clean numbers\n",
    "    test['comment_text'] = test['comment_text'].apply(clean_numbers)\n",
    "    \n",
    "    # strip\n",
    "    test['comment_text'] = test['comment_text'].str.strip()\n",
    "    \n",
    "    # replace blank with nan\n",
    "    test['comment_text'].replace('', np.nan, inplace=True)\n",
    "\n",
    "    \n",
    "    # fill up the missing values\n",
    "    test_x = test['comment_text'].fillna('_##_').values\n",
    "    \n",
    "    # get the target values\n",
    "    identity_columns = [\n",
    "        'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "        'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "\n",
    "\n",
    "    return test_x\n",
    "\n",
    "class JigsawEvaluator:\n",
    "    \n",
    "    def __init__(self, y_binary, y_identity_binary, power=-5, overall_model_weight=0.25):\n",
    "        self.y = y_binary\n",
    "        self.y_i = y_identity_binary\n",
    "        self.n_subgroups = self.y_i.shape[1]\n",
    "        self.power = power\n",
    "        self.overall_model_weight = overall_model_weight\n",
    "        \n",
    "    @staticmethod\n",
    "    def _compute_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "        \n",
    "    def _compute_subgroup_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] == 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "        \n",
    "    def _compute_bpsn_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] + self.y == 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "        \n",
    "    def _compute_bnsp_auc(self, i, y_pred):\n",
    "        mask = self.y_i[:, i] + self.y != 1\n",
    "        return self._compute_auc(self.y[mask], y_pred[mask])\n",
    "        \n",
    "    def compute_bias_metrics_for_model(self, y_pred):\n",
    "        records = np.zeros((3, self.n_subgroups))\n",
    "        for i in range(self.n_subgroups):\n",
    "            records[0, i] = self._compute_subgroup_auc(i, y_pred)\n",
    "            records[1, i] = self._compute_bpsn_auc(i, y_pred)\n",
    "            records[2, i] = self._compute_bnsp_auc(i, y_pred)\n",
    "        return records\n",
    "        \n",
    "    def _calculate_overall_auc(self, y_pred):\n",
    "        return roc_auc_score(self.y, y_pred)\n",
    "        \n",
    "    def _power_mean(self, array):\n",
    "        total = sum(np.power(array, self.power))\n",
    "        return np.power(total / len(array), 1 / self.power)\n",
    "        \n",
    "    def get_final_metric(self, y_pred):\n",
    "        bias_metrics = self.compute_bias_metrics_for_model(y_pred)\n",
    "        bias_score = np.average([\n",
    "            self._power_mean(bias_metrics[0]),\n",
    "            self._power_mean(bias_metrics[1]),\n",
    "            self._power_mean(bias_metrics[2])\n",
    "        ])\n",
    "        overall_score = self.overall_model_weight * self._calculate_overall_auc(y_pred)\n",
    "        bias_score = (1 - self.overall_model_weight) * bias_score\n",
    "        return overall_score + bias_score\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader):\n",
    "    model.eval()\n",
    "    preds_fold = np.zeros(len(data_loader.dataset))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            y_pred = model(x_batch).detach()\n",
    "            preds_fold[list(index)] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "    return preds_fold\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        lstm_hidden_size = 120\n",
    "        gru_hidden_size = 60\n",
    "        self.gru_hidden_size = gru_hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(*embedding_matrix.shape)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.embedding_dropout = nn.Dropout2d(0.2)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_matrix.shape[1], lstm_hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.gru = nn.GRU(lstm_hidden_size * 2, gru_hidden_size, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Linear(gru_hidden_size * 6, 20)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Linear(20, 1)\n",
    "        \n",
    "    def apply_spatial_dropout(self, h_embedding):\n",
    "        h_embedding = h_embedding.transpose(1, 2).unsqueeze(2)\n",
    "        h_embedding = self.embedding_dropout(h_embedding).squeeze(2).transpose(1, 2)\n",
    "        return h_embedding\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = self.apply_spatial_dropout(h_embedding)\n",
    "\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        h_gru, hh_gru = self.gru(h_lstm)\n",
    "\n",
    "        hh_gru = hh_gru.view(-1, self.gru_hidden_size * 2)\n",
    "\n",
    "        avg_pool = torch.mean(h_gru, 1)\n",
    "        max_pool, _ = torch.max(h_gru, 1)\n",
    "\n",
    "        conc = torch.cat((hh_gru, avg_pool, max_pool), 1)\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "        out = self.out(conc)\n",
    "\n",
    "        return out\n",
    "\n",
    "class BucketSampler(Sampler):\n",
    "\n",
    "    def __init__(self, data_source, sort_keys, bucket_size=None, batch_size=1048, shuffle_data=True):\n",
    "        super().__init__(data_source)\n",
    "        self.shuffle = shuffle_data\n",
    "        self.batch_size = batch_size\n",
    "        self.sort_keys = sort_keys\n",
    "        self.bucket_size = bucket_size if bucket_size is not None else len(sort_keys)\n",
    "        self.weights = None\n",
    "\n",
    "        if not shuffle_data:\n",
    "            self.index = self.prepare_buckets()\n",
    "        else:\n",
    "            self.index = None\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        assert weights >= 0\n",
    "        total = np.sum(weights)\n",
    "        if total != 1:\n",
    "            weights = weights / total\n",
    "        self.weights = weights\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = None\n",
    "        if self.weights is not None:\n",
    "            total = len(self.sort_keys)\n",
    "            indices = np.random.choice(total, (total,), p=self.weights)\n",
    "        if self.shuffle:\n",
    "            self.index = self.prepare_buckets(indices)\n",
    "        return iter(self.index)\n",
    "\n",
    "    def get_reverse_indexes(self):\n",
    "        indexes = np.zeros((len(self.index),), dtype=np.int32)\n",
    "        for i, j in enumerate(self.index):\n",
    "            indexes[j] = i\n",
    "        return indexes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sort_keys)\n",
    "        \n",
    "    def prepare_buckets(self, indices=None):\n",
    "        lens = - self.sort_keys\n",
    "        assert self.bucket_size % self.batch_size == 0 or self.bucket_size == len(lens)\n",
    "\n",
    "        if indices is None:\n",
    "            if self.shuffle:\n",
    "                indices = shuffle(np.arange(len(lens), dtype=np.int32))\n",
    "                lens = lens[indices]\n",
    "            else:\n",
    "                indices = np.arange(len(lens), dtype=np.int32)\n",
    "\n",
    "        #  bucket iterator\n",
    "        def divide_chunks(l, n):\n",
    "            if n == len(l):\n",
    "                yield np.arange(len(l), dtype=np.int32), l\n",
    "            else:\n",
    "                # looping till length l\n",
    "                for i in range(0, len(l), n):\n",
    "                    data = l[i:i + n]\n",
    "                    yield np.arange(i, i + len(data), dtype=np.int32), data\n",
    "    \n",
    "        new_indices = []\n",
    "        extra_batch = None\n",
    "        for chunk_index, chunk in divide_chunks(lens, self.bucket_size):\n",
    "            # sort indices in bucket by descending order of length\n",
    "            indices_sorted = chunk_index[np.argsort(chunk, axis=-1)]\n",
    "            batches = []\n",
    "            for _, batch in divide_chunks(indices_sorted, self.batch_size):\n",
    "                if len(batch) == self.batch_size:\n",
    "                    batches.append(batch.tolist())\n",
    "                else:\n",
    "                    assert extra_batch is None\n",
    "                    assert batch is not None\n",
    "                    extra_batch = batch\n",
    "    \n",
    "            # shuffling batches within buckets\n",
    "            if self.shuffle:\n",
    "                batches = shuffle(batches)\n",
    "            for batch in batches:\n",
    "                new_indices.extend(batch)\n",
    "    \n",
    "        if extra_batch is not None:\n",
    "            new_indices.extend(extra_batch)\n",
    "        return indices[new_indices]\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, seqs, targets=None, maxlen=200):\n",
    "        if targets is not None:\n",
    "            self.targets = targets\n",
    "        else:\n",
    "            self.targets = np.random.randint(2, size=(len(seqs),))\n",
    "        \n",
    "        self.seqs = seqs\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "        \n",
    "    def get_keys(self):\n",
    "        lens = np.fromiter(\n",
    "            ((min(self.maxlen, len(seq))) for seq in self.seqs),\n",
    "            dtype=np.int32)\n",
    "        return lens\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return index, self.seqs[index], self.targets[index]\n",
    "\n",
    "def collate_fn(data):\n",
    "    def _pad_sequences(seqs):\n",
    "        lens = [len(seq) for seq in seqs]\n",
    "        max_len = max(lens)\n",
    "\n",
    "        padded_seqs = torch.zeros(len(seqs), max_len).long()\n",
    "        for i, seq in enumerate(seqs):\n",
    "            start = max_len - lens[i]\n",
    "            padded_seqs[i, start:] = torch.LongTensor(seq)\n",
    "        return padded_seqs\n",
    "\n",
    "    index, seqs, targets = zip(*data)\n",
    "    seqs = _pad_sequences(seqs)\n",
    "    return index, seqs, torch.FloatTensor(targets)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def eval_model(model, data_loader):\n",
    "    model.eval()\n",
    "    preds_fold = np.zeros(len(data_loader.dataset))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, x_batch, y_batch in data_loader:\n",
    "            x_batch = x_batch.to(\"cuda\")\n",
    "            y_batch = y_batch.to(\"cuda\")\n",
    "            y_pred = model(x_batch).detach()\n",
    "            preds_fold[list(index)] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "\n",
    "    return preds_fold\n",
    "\n",
    "\n",
    "def tokenize(texts, vocab):\n",
    "\n",
    "    def text2ids(text, token2id):\n",
    "        return [\n",
    "            token2id.get(token, len(token2id) - 1)\n",
    "            for token in text.split()[:max_len]] + [0] * max(0, max_len - len(text.split()))\n",
    "    \n",
    "    return [\n",
    "        text2ids(text, vocab['token2id'])\n",
    "        for text in texts]\n",
    "\n",
    "\n",
    "def load_embedding(embedding_path, word_index):\n",
    "\n",
    "    def get_coefs(word, *arr):\n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "    embeddings_index = dict(get_coefs(*o.strip().split(' ')) for o in open(embedding_path))\n",
    "    \n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features + 2, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "\n",
    "    for key, i in word_index.items():\n",
    "        word = key\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = key.lower()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = key.upper()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = key.capitalize()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = ps.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = lc.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "        word = sb.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            continue\n",
    "\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.json', 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "embedding_matrix = load_embedding(EMBEDDING_FASTTEXT, vocab['token2id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dkushn/Ethics_NYU_2024_Spring/respethics/respethics/lib/python3.11/site-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n"
     ]
    }
   ],
   "source": [
    "test_data = {\"private\": test_private_df, \"public\": test_public_df, \"combined\": test_combined_df}\n",
    "test_x = {}\n",
    "test_dataset = {}\n",
    "test_sampler = {}\n",
    "test_loader = {}\n",
    "\n",
    "for key, df in test_data.items():\n",
    "    test_x[key] = load_and_prec(df)\n",
    "    test_x[key] = np.array(tokenize(test_x[key], vocab))\n",
    "    test_dataset[key] = TextDataset(test_x[key], maxlen=max_len)\n",
    "    test_sampler[key] = BucketSampler(test_dataset[key], test_dataset[key].get_keys(),\n",
    "                                 batch_size=batch_size, shuffle_data=False)\n",
    "\n",
    "    test_loader[key] = DataLoader(test_dataset[key], batch_size=batch_size, sampler=test_sampler[key],\n",
    "                             shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading models: 100%|██████████| 37/37 [00:07<00:00,  4.68it/s]\n"
     ]
    }
   ],
   "source": [
    "models = torch.load('./experiments/model_baseline.pt')\n",
    "models.keys()\n",
    "\n",
    "for name in tqdm(models.keys(), total=len(models), desc='Loading models'):\n",
    "    new_model = NeuralNet(embedding_matrix).to(\"cuda\")\n",
    "    new_model.load_state_dict(models[name])\n",
    "    models[name] = new_model\n",
    "    models[name].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inference(comments, models):\n",
    "    test_x = np.array(tokenize(comments, vocab))\n",
    "    test_dataset = TextDataset(test_x, maxlen=max_len)\n",
    "    test_sampler = BucketSampler(test_dataset, test_dataset.get_keys(),\n",
    "                                 batch_size=batch_size, shuffle_data=False)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler,\n",
    "                             shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    preds = []\n",
    "    ema_preds = []\n",
    "    \n",
    "    first_phase_preds = [eval_model(models[\"model\"], test_loader), eval_model(models[\"ema_model\"], test_loader)]\n",
    "\n",
    "\n",
    "    for name, model in tqdm(models.items(), total=len(models), desc='Evaluating models'):\n",
    "        # skip first phase\n",
    "        if name in [\"model\", \"ema_model\"]:\n",
    "            continue\n",
    "\n",
    "        if name.startswith('ema'):\n",
    "            ema_preds.append(eval_model(model, test_loader))\n",
    "        else:\n",
    "            preds.append(eval_model(model, test_loader))\n",
    "    preds = np.mean(preds, axis=0)\n",
    "    ema_preds = np.mean(ema_preds, axis=0)\n",
    "    return np.mean([preds, ema_preds], axis=0) * 0.9 + np.mean(first_phase_preds, axis=0) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating models: 100%|██████████| 37/37 [06:56<00:00, 11.27s/it]\n",
      "/home/dkushn/Ethics_NYU_2024_Spring/respethics/respethics/lib/python3.11/site-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
      "Evaluating models: 100%|██████████| 37/37 [07:54<00:00, 12.83s/it]\n",
      "/home/dkushn/Ethics_NYU_2024_Spring/respethics/respethics/lib/python3.11/site-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
      "Evaluating models: 100%|██████████| 37/37 [15:55<00:00, 25.81s/it]\n"
     ]
    }
   ],
   "source": [
    "for key, df in test_data.items():\n",
    "    preds = inference(df[\"comment_text\"].to_list(), models)\n",
    "    df[\"prediction\"] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = inference(test[\"comment_text\"].to_list(), models)\n",
    "# test[\"prediction\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private 0.8364739924210273\n",
      "public 0.829694372778121\n",
      "combined 0.8332936019791147\n"
     ]
    }
   ],
   "source": [
    "for key, df in test_data.items():\n",
    "    roc_auc_ = roc_auc_score((df['toxicity'] >= 0.5).astype(int), (df['prediction'] >= 0.5).astype(int)) # TODO: must be by group\n",
    "    print (key, roc_auc_)\n",
    "\n",
    "# print(roc_auc_score((test['toxicity'] >= 0.5).astype(int), (test['prediction'] >= 0.5).astype(int))) # TODO: must be by group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into different subpopulations and plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['funny',\n",
       "  'wow',\n",
       "  'sad',\n",
       "  'likes',\n",
       "  'disagree',\n",
       "  'toxicity',\n",
       "  'male',\n",
       "  'female',\n",
       "  'transgender',\n",
       "  'other_gender',\n",
       "  'heterosexual',\n",
       "  'homosexual_gay_or_lesbian',\n",
       "  'bisexual',\n",
       "  'other_sexual_orientation',\n",
       "  'christian',\n",
       "  'jewish',\n",
       "  'muslim',\n",
       "  'hindu',\n",
       "  'buddhist',\n",
       "  'atheist',\n",
       "  'other_religion',\n",
       "  'black',\n",
       "  'white',\n",
       "  'asian',\n",
       "  'latino',\n",
       "  'other_race_or_ethnicity',\n",
       "  'physical_disability',\n",
       "  'intellectual_or_learning_disability',\n",
       "  'psychiatric_or_mental_illness',\n",
       "  'other_disability'],\n",
       " 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_remove = ['comment_text', 'created_date', 'publication_id', 'parent_id', 'article_id', 'rating', \"identity_annotator_count\", \"toxicity_annotator_count\"]\n",
    "out_of_competition_traits = [\"severe_toxicity\", \"obscene\", \"identity_attack\", \"insult\", \"threat\", \"sexual_explicit\"]\n",
    "columns_to_remove += out_of_competition_traits\n",
    "\n",
    "subpopulations = [i for i in test.columns.to_list() if i not in columns_to_remove]\n",
    "subpopulations, len(subpopulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We’ll split our data into different subpopulations and plot distributions in Colab.\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# plot_columns = 3\n",
    "# plot_rows = len(subpopulations) // plot_columns + 1\n",
    "\n",
    "# plt.figure(figsize=(12, 40))\n",
    "# plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "# for i, subpopulation in enumerate(subpopulations):\n",
    "#     plt.subplot(plot_rows, plot_columns, i+1)\n",
    "#     sns.histplot(test[subpopulation], bins=30)#, kde=True)\n",
    "#     plt.title(subpopulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# plot_columns = 3\n",
    "# plot_rows = len(subpopulations) // plot_columns + 1\n",
    "\n",
    "# plt.figure(figsize=(12, 40))\n",
    "# plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "# for i, subpopulation in enumerate(subpopulations):\n",
    "#     plt.subplot(plot_rows, plot_columns, i+1)\n",
    "#     # get number of bins \n",
    "#     n_bins = 30 #test[subpopulation][test[subpopulation] != test[subpopulation].min()].nunique()\n",
    "#     sns.histplot(test[subpopulation][test[subpopulation] != test[subpopulation].min()], bins=n_bins)#, kde=True)\n",
    "#     plt.title(subpopulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>public</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>0.861159</td>\n",
       "      <td>0.861344</td>\n",
       "      <td>0.861252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>0.961683</td>\n",
       "      <td>0.960501</td>\n",
       "      <td>0.961092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.921948</td>\n",
       "      <td>0.922277</td>\n",
       "      <td>0.922113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>0.412916</td>\n",
       "      <td>0.413615</td>\n",
       "      <td>0.413266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disagree</th>\n",
       "      <td>0.773962</td>\n",
       "      <td>0.773130</td>\n",
       "      <td>0.773546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicity</th>\n",
       "      <td>0.701510</td>\n",
       "      <td>0.706176</td>\n",
       "      <td>0.703843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.180425</td>\n",
       "      <td>0.176808</td>\n",
       "      <td>0.178617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.184001</td>\n",
       "      <td>0.181556</td>\n",
       "      <td>0.182778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transgender</th>\n",
       "      <td>0.218598</td>\n",
       "      <td>0.215464</td>\n",
       "      <td>0.217031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_gender</th>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.217293</td>\n",
       "      <td>0.218830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heterosexual</th>\n",
       "      <td>0.219831</td>\n",
       "      <td>0.217139</td>\n",
       "      <td>0.218485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <td>0.214190</td>\n",
       "      <td>0.211087</td>\n",
       "      <td>0.212639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bisexual</th>\n",
       "      <td>0.219831</td>\n",
       "      <td>0.217119</td>\n",
       "      <td>0.218475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <td>0.219441</td>\n",
       "      <td>0.216358</td>\n",
       "      <td>0.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christian</th>\n",
       "      <td>0.188471</td>\n",
       "      <td>0.186108</td>\n",
       "      <td>0.187289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jewish</th>\n",
       "      <td>0.215732</td>\n",
       "      <td>0.212608</td>\n",
       "      <td>0.214170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muslim</th>\n",
       "      <td>0.207994</td>\n",
       "      <td>0.205682</td>\n",
       "      <td>0.206838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hindu</th>\n",
       "      <td>0.220849</td>\n",
       "      <td>0.218033</td>\n",
       "      <td>0.219441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buddhist</th>\n",
       "      <td>0.221003</td>\n",
       "      <td>0.218115</td>\n",
       "      <td>0.219559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atheist</th>\n",
       "      <td>0.219780</td>\n",
       "      <td>0.217047</td>\n",
       "      <td>0.218413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_religion</th>\n",
       "      <td>0.213224</td>\n",
       "      <td>0.209977</td>\n",
       "      <td>0.211601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.211539</td>\n",
       "      <td>0.208508</td>\n",
       "      <td>0.210024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>0.206998</td>\n",
       "      <td>0.203093</td>\n",
       "      <td>0.205045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asian</th>\n",
       "      <td>0.215999</td>\n",
       "      <td>0.213368</td>\n",
       "      <td>0.214684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latino</th>\n",
       "      <td>0.217674</td>\n",
       "      <td>0.215136</td>\n",
       "      <td>0.216405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <td>0.212454</td>\n",
       "      <td>0.209505</td>\n",
       "      <td>0.210979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical_disability</th>\n",
       "      <td>0.219955</td>\n",
       "      <td>0.217109</td>\n",
       "      <td>0.218532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <td>0.220160</td>\n",
       "      <td>0.217047</td>\n",
       "      <td>0.218604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <td>0.215978</td>\n",
       "      <td>0.212998</td>\n",
       "      <td>0.214488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_disability</th>\n",
       "      <td>0.219770</td>\n",
       "      <td>0.216975</td>\n",
       "      <td>0.218372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      private    public  combined\n",
       "funny                                0.861159  0.861344  0.861252\n",
       "wow                                  0.961683  0.960501  0.961092\n",
       "sad                                  0.921948  0.922277  0.922113\n",
       "likes                                0.412916  0.413615  0.413266\n",
       "disagree                             0.773962  0.773130  0.773546\n",
       "toxicity                             0.701510  0.706176  0.703843\n",
       "male                                 0.180425  0.176808  0.178617\n",
       "female                               0.184001  0.181556  0.182778\n",
       "transgender                          0.218598  0.215464  0.217031\n",
       "other_gender                         0.220366  0.217293  0.218830\n",
       "heterosexual                         0.219831  0.217139  0.218485\n",
       "homosexual_gay_or_lesbian            0.214190  0.211087  0.212639\n",
       "bisexual                             0.219831  0.217119  0.218475\n",
       "other_sexual_orientation             0.219441  0.216358  0.217900\n",
       "christian                            0.188471  0.186108  0.187289\n",
       "jewish                               0.215732  0.212608  0.214170\n",
       "muslim                               0.207994  0.205682  0.206838\n",
       "hindu                                0.220849  0.218033  0.219441\n",
       "buddhist                             0.221003  0.218115  0.219559\n",
       "atheist                              0.219780  0.217047  0.218413\n",
       "other_religion                       0.213224  0.209977  0.211601\n",
       "black                                0.211539  0.208508  0.210024\n",
       "white                                0.206998  0.203093  0.205045\n",
       "asian                                0.215999  0.213368  0.214684\n",
       "latino                               0.217674  0.215136  0.216405\n",
       "other_race_or_ethnicity              0.212454  0.209505  0.210979\n",
       "physical_disability                  0.219955  0.217109  0.218532\n",
       "intellectual_or_learning_disability  0.220160  0.217047  0.218604\n",
       "psychiatric_or_mental_illness        0.215978  0.212998  0.214488\n",
       "other_disability                     0.219770  0.216975  0.218372"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percent of values that are 0\n",
    "mean_representation = {}\n",
    "for key, df in test_data.items():\n",
    "    mean_representation[key] = (df[subpopulations] == 0).mean()\n",
    "\n",
    "mean_representation_df = pd.DataFrame(mean_representation)\n",
    "mean_representation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'created_date', 'publication_id', 'parent_id',\n",
       "       'article_id', 'rating', 'funny', 'wow', 'sad', 'likes', 'disagree',\n",
       "       'toxicity', 'severe_toxicity', 'obscene', 'sexual_explicit',\n",
       "       'identity_attack', 'insult', 'threat', 'identity_annotator_count',\n",
       "       'toxicity_annotator_count', 'male', 'female', 'transgender',\n",
       "       'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual',\n",
       "       'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu',\n",
       "       'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian',\n",
       "       'latino', 'other_race_or_ethnicity', 'physical_disability',\n",
       "       'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
       "       'other_disability', 'prediction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"combined\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No positive cases of subpopulation in private other_gender\n",
      "No positive cases of subpopulation in private other_sexual_orientation\n",
      "Only one toxic example for subpopulation in private other_religion\n",
      "Only one toxic example for subpopulation in private physical_disability\n",
      "Only one toxic example for subpopulation in private intellectual_or_learning_disability\n",
      "No positive cases of subpopulation in private other_disability\n",
      "No positive cases of subpopulation in public other_gender\n",
      "No positive cases of subpopulation in public other_sexual_orientation\n",
      "Only one toxic example for subpopulation in public other_religion\n",
      "Only one toxic example for subpopulation in public other_race_or_ethnicity\n",
      "Only one toxic example for subpopulation in public physical_disability\n",
      "Only one toxic example for subpopulation in public intellectual_or_learning_disability\n",
      "No positive cases of subpopulation in public other_disability\n",
      "No positive cases of subpopulation in combined other_gender\n",
      "No positive cases of subpopulation in combined other_sexual_orientation\n",
      "Only one toxic example for subpopulation in combined other_religion\n",
      "Only one toxic example for subpopulation in combined physical_disability\n",
      "Only one toxic example for subpopulation in combined intellectual_or_learning_disability\n",
      "No positive cases of subpopulation in combined other_disability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subpopulation</th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funny</td>\n",
       "      <td>0.837922</td>\n",
       "      <td>0.022773</td>\n",
       "      <td>0.301382</td>\n",
       "      <td>0.954855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wow</td>\n",
       "      <td>0.816492</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.343109</td>\n",
       "      <td>0.946903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>0.823013</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>0.329218</td>\n",
       "      <td>0.946024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>likes</td>\n",
       "      <td>0.823526</td>\n",
       "      <td>0.021411</td>\n",
       "      <td>0.331536</td>\n",
       "      <td>0.954424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disagree</td>\n",
       "      <td>0.822518</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.330266</td>\n",
       "      <td>0.948132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>0.772854</td>\n",
       "      <td>0.037332</td>\n",
       "      <td>0.416961</td>\n",
       "      <td>0.906625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>0.778424</td>\n",
       "      <td>0.023212</td>\n",
       "      <td>0.419940</td>\n",
       "      <td>0.923014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transgender</td>\n",
       "      <td>0.712366</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.837607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heterosexual</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>0.708907</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.799180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bisexual</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>christian</td>\n",
       "      <td>0.727243</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.926439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jewish</td>\n",
       "      <td>0.721381</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>muslim</td>\n",
       "      <td>0.704564</td>\n",
       "      <td>0.050331</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.838280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hindu</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>buddhist</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>atheist</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>black</td>\n",
       "      <td>0.710036</td>\n",
       "      <td>0.082073</td>\n",
       "      <td>0.497854</td>\n",
       "      <td>0.778736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>white</td>\n",
       "      <td>0.720894</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>asian</td>\n",
       "      <td>0.797824</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.951515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>latino</td>\n",
       "      <td>0.723443</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.825581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>other_race_or_ethnicity</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>0.843247</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.899497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    subpopulation   AUC ROC  False Positive Rate  \\\n",
       "0                           funny  0.837922             0.022773   \n",
       "1                             wow  0.816492             0.023908   \n",
       "2                             sad  0.823013             0.024756   \n",
       "3                           likes  0.823526             0.021411   \n",
       "4                        disagree  0.822518             0.024698   \n",
       "5                            male  0.772854             0.037332   \n",
       "6                          female  0.778424             0.023212   \n",
       "7                     transgender  0.712366             0.075269   \n",
       "8                    heterosexual  0.840909             0.068182   \n",
       "9       homosexual_gay_or_lesbian  0.708907             0.075145   \n",
       "10                       bisexual  0.750000             0.000000   \n",
       "11                      christian  0.727243             0.020262   \n",
       "12                         jewish  0.721381             0.034161   \n",
       "13                         muslim  0.704564             0.050331   \n",
       "14                          hindu  0.500000             0.000000   \n",
       "15                       buddhist  0.500000             0.000000   \n",
       "16                        atheist  0.692308             0.015385   \n",
       "17                          black  0.710036             0.082073   \n",
       "18                          white  0.720894             0.078680   \n",
       "19                          asian  0.797824             0.019737   \n",
       "20                         latino  0.723443             0.076923   \n",
       "21        other_race_or_ethnicity  0.500000             0.000000   \n",
       "22  psychiatric_or_mental_illness  0.843247             0.057692   \n",
       "\n",
       "    False Negative Rate  Accuracy  \n",
       "0              0.301382  0.954855  \n",
       "1              0.343109  0.946903  \n",
       "2              0.329218  0.946024  \n",
       "3              0.331536  0.954424  \n",
       "4              0.330266  0.948132  \n",
       "5              0.416961  0.906625  \n",
       "6              0.419940  0.923014  \n",
       "7              0.500000  0.837607  \n",
       "8              0.250000  0.892857  \n",
       "9              0.507042  0.799180  \n",
       "10             0.500000  0.937500  \n",
       "11             0.525253  0.926439  \n",
       "12             0.523077  0.883721  \n",
       "13             0.540541  0.838280  \n",
       "14             1.000000  0.920000  \n",
       "15             1.000000  0.875000  \n",
       "16             0.600000  0.942857  \n",
       "17             0.497854  0.778736  \n",
       "18             0.479532  0.800000  \n",
       "19             0.384615  0.951515  \n",
       "20             0.476190  0.825581  \n",
       "21             1.000000  0.800000  \n",
       "22             0.255814  0.899497  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "results_data = {}\n",
    "\n",
    "for key, df in test_data.items():\n",
    "    results_data[key] = pd.DataFrame(columns=[\"subpopulation\", \"AUC ROC\", \"False Positive Rate\", \"False Negative Rate\", \"Accuracy\"])\n",
    "    for subpopulation in subpopulations:\n",
    "        if subpopulation in [\"toxicity\", \"prediction\"]:\n",
    "            continue\n",
    "        if len(df[df[subpopulation] > 0.5]) == 0:\n",
    "            print(f\"No positive cases of subpopulation in {key}\", subpopulation)\n",
    "            continue\n",
    "        if len((df[df[subpopulation] > 0.5]['toxicity'] >= 0.5).astype(int).value_counts()) == 1:\n",
    "            print(f\"Only one toxic example for subpopulation in {key}\", subpopulation)\n",
    "            continue\n",
    "        \n",
    "        fp = ((df[df[subpopulation] > 0.5]['toxicity'] < 0.5) & (df[df[subpopulation] > 0.5]['prediction'] >= 0.5)).sum()\n",
    "        fn = ((df[df[subpopulation] > 0.5]['toxicity'] >= 0.5) & (df[df[subpopulation] > 0.5]['prediction'] < 0.5)).sum()\n",
    "        tp = ((df[df[subpopulation] > 0.5]['toxicity'] >= 0.5) & (df[df[subpopulation] > 0.5]['prediction'] >= 0.5)).sum()\n",
    "        tn = ((df[df[subpopulation] > 0.5]['toxicity'] < 0.5) & (df[df[subpopulation] > 0.5]['prediction'] < 0.5)).sum()\n",
    "\n",
    "\n",
    "        auc_roc_score = roc_auc_score((df[df[subpopulation] > 0.5]['toxicity'] >= 0.5).astype(int), (df[df[subpopulation] > 0.5]['prediction'] >= 0.5).astype(int))\n",
    "        false_positive_rate = fp / (fp + tn)\n",
    "        false_negative_rate = fn / (fn + tp)\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Create a new DataFrame with the new rows\n",
    "        new_rows = pd.DataFrame({\"subpopulation\": [subpopulation],\n",
    "                                 \"AUC ROC\": [auc_roc_score],\n",
    "                                 \"False Positive Rate\": [false_positive_rate],\n",
    "                                 \"False Negative Rate\": [false_negative_rate],\n",
    "                                 \"Accuracy\": [accuracy]})\n",
    "\n",
    "        # Concatenate the new DataFrame with the original DataFrame\n",
    "        results_data[key] = pd.concat([results_data[key], new_rows], ignore_index=True)\n",
    "\n",
    "results_data['private']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case A:\n",
    "# labels = subpopulations\n",
    "# labels.remove('toxicity')\n",
    "# labels.remove('prediction')\n",
    "\n",
    "# case B:\n",
    "labels = identity_columns\n",
    "\n",
    "bias_metrics = {}\n",
    "overall_auc = {}\n",
    "for key, df in test_data.items():\n",
    "    bias_metrics[key] = {}\n",
    "    test_y_identity_binary = (df[labels].values >= 0.5).astype(int)\n",
    "    test_y_binary = (df['toxicity'].values >= 0.5).astype(int)\n",
    "    evaluator = JigsawEvaluator(test_y_binary, test_y_identity_binary)\n",
    "    \n",
    "    test_nan_mask = df == '_##_'\n",
    "    assert test_nan_mask.values.sum() == 0\n",
    "\n",
    "    overall_auc[key] = evaluator._calculate_overall_auc(df[\"prediction\"])\n",
    "    bias_metrics_dict = evaluator.compute_bias_metrics_for_model(df[\"prediction\"])\n",
    "    bias_metrics[key] = pd.DataFrame(bias_metrics_dict, index=[\"Subgroup_AUC\", \"BPSN_AUC\", \"BNSP_AUC\"], columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subgroup_AUC</th>\n",
       "      <td>0.926783</td>\n",
       "      <td>0.936878</td>\n",
       "      <td>0.846207</td>\n",
       "      <td>0.945133</td>\n",
       "      <td>0.919489</td>\n",
       "      <td>0.875941</td>\n",
       "      <td>0.857845</td>\n",
       "      <td>0.870107</td>\n",
       "      <td>0.925250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSN_AUC</th>\n",
       "      <td>0.952674</td>\n",
       "      <td>0.961249</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>0.967997</td>\n",
       "      <td>0.944118</td>\n",
       "      <td>0.919214</td>\n",
       "      <td>0.885209</td>\n",
       "      <td>0.896128</td>\n",
       "      <td>0.931262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNSP_AUC</th>\n",
       "      <td>0.957425</td>\n",
       "      <td>0.955850</td>\n",
       "      <td>0.958942</td>\n",
       "      <td>0.952781</td>\n",
       "      <td>0.959865</td>\n",
       "      <td>0.959340</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.967663</td>\n",
       "      <td>0.968772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  male    female  homosexual_gay_or_lesbian  christian  \\\n",
       "Subgroup_AUC  0.926783  0.936878                   0.846207   0.945133   \n",
       "BPSN_AUC      0.952674  0.961249                   0.898955   0.967997   \n",
       "BNSP_AUC      0.957425  0.955850                   0.958942   0.952781   \n",
       "\n",
       "                jewish    muslim     black     white  \\\n",
       "Subgroup_AUC  0.919489  0.875941  0.857845  0.870107   \n",
       "BPSN_AUC      0.944118  0.919214  0.885209  0.896128   \n",
       "BNSP_AUC      0.959865  0.959340  0.967532  0.967663   \n",
       "\n",
       "              psychiatric_or_mental_illness  \n",
       "Subgroup_AUC                       0.925250  \n",
       "BPSN_AUC                           0.931262  \n",
       "BNSP_AUC                           0.968772  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_metrics['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subgroup_AUC</th>\n",
       "      <td>0.924933</td>\n",
       "      <td>0.934857</td>\n",
       "      <td>0.846999</td>\n",
       "      <td>0.946266</td>\n",
       "      <td>0.928208</td>\n",
       "      <td>0.895614</td>\n",
       "      <td>0.859239</td>\n",
       "      <td>0.875779</td>\n",
       "      <td>0.900278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSN_AUC</th>\n",
       "      <td>0.952606</td>\n",
       "      <td>0.958334</td>\n",
       "      <td>0.896844</td>\n",
       "      <td>0.967188</td>\n",
       "      <td>0.946509</td>\n",
       "      <td>0.918229</td>\n",
       "      <td>0.871877</td>\n",
       "      <td>0.894011</td>\n",
       "      <td>0.925083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNSP_AUC</th>\n",
       "      <td>0.956545</td>\n",
       "      <td>0.957160</td>\n",
       "      <td>0.959691</td>\n",
       "      <td>0.954294</td>\n",
       "      <td>0.962221</td>\n",
       "      <td>0.965325</td>\n",
       "      <td>0.971576</td>\n",
       "      <td>0.969131</td>\n",
       "      <td>0.961179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  male    female  homosexual_gay_or_lesbian  christian  \\\n",
       "Subgroup_AUC  0.924933  0.934857                   0.846999   0.946266   \n",
       "BPSN_AUC      0.952606  0.958334                   0.896844   0.967188   \n",
       "BNSP_AUC      0.956545  0.957160                   0.959691   0.954294   \n",
       "\n",
       "                jewish    muslim     black     white  \\\n",
       "Subgroup_AUC  0.928208  0.895614  0.859239  0.875779   \n",
       "BPSN_AUC      0.946509  0.918229  0.871877  0.894011   \n",
       "BNSP_AUC      0.962221  0.965325  0.971576  0.969131   \n",
       "\n",
       "              psychiatric_or_mental_illness  \n",
       "Subgroup_AUC                       0.900278  \n",
       "BPSN_AUC                           0.925083  \n",
       "BNSP_AUC                           0.961179  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_metrics['public']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subgroup_AUC</th>\n",
       "      <td>0.929150</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>0.844409</td>\n",
       "      <td>0.943938</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.855740</td>\n",
       "      <td>0.856216</td>\n",
       "      <td>0.863264</td>\n",
       "      <td>0.946961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BPSN_AUC</th>\n",
       "      <td>0.952718</td>\n",
       "      <td>0.964037</td>\n",
       "      <td>0.900879</td>\n",
       "      <td>0.968860</td>\n",
       "      <td>0.941736</td>\n",
       "      <td>0.920468</td>\n",
       "      <td>0.897919</td>\n",
       "      <td>0.898213</td>\n",
       "      <td>0.937887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNSP_AUC</th>\n",
       "      <td>0.958613</td>\n",
       "      <td>0.954651</td>\n",
       "      <td>0.958159</td>\n",
       "      <td>0.951316</td>\n",
       "      <td>0.957288</td>\n",
       "      <td>0.952754</td>\n",
       "      <td>0.963243</td>\n",
       "      <td>0.966051</td>\n",
       "      <td>0.976276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  male    female  homosexual_gay_or_lesbian  christian  \\\n",
       "Subgroup_AUC  0.929150  0.938965                   0.844409   0.943938   \n",
       "BPSN_AUC      0.952718  0.964037                   0.900879   0.968860   \n",
       "BNSP_AUC      0.958613  0.954651                   0.958159   0.951316   \n",
       "\n",
       "                jewish    muslim     black     white  \\\n",
       "Subgroup_AUC  0.910821  0.855740  0.856216  0.863264   \n",
       "BPSN_AUC      0.941736  0.920468  0.897919  0.898213   \n",
       "BNSP_AUC      0.957288  0.952754  0.963243  0.966051   \n",
       "\n",
       "              psychiatric_or_mental_illness  \n",
       "Subgroup_AUC                       0.946961  \n",
       "BPSN_AUC                           0.937887  \n",
       "BNSP_AUC                           0.976276  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_metrics['private']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subpopulation</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC ROC</th>\n",
       "      <td>0.766717</td>\n",
       "      <td>0.771612</td>\n",
       "      <td>0.707799</td>\n",
       "      <td>0.722610</td>\n",
       "      <td>0.735562</td>\n",
       "      <td>0.715793</td>\n",
       "      <td>0.718407</td>\n",
       "      <td>0.731150</td>\n",
       "      <td>0.792904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.039431</td>\n",
       "      <td>0.025555</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.018697</td>\n",
       "      <td>0.028875</td>\n",
       "      <td>0.050871</td>\n",
       "      <td>0.092973</td>\n",
       "      <td>0.075077</td>\n",
       "      <td>0.048338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.431221</td>\n",
       "      <td>0.516605</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.470213</td>\n",
       "      <td>0.462623</td>\n",
       "      <td>0.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.902267</td>\n",
       "      <td>0.920149</td>\n",
       "      <td>0.807967</td>\n",
       "      <td>0.927106</td>\n",
       "      <td>0.891414</td>\n",
       "      <td>0.836594</td>\n",
       "      <td>0.779928</td>\n",
       "      <td>0.807198</td>\n",
       "      <td>0.888620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subpopulation            male    female  homosexual_gay_or_lesbian  christian  \\\n",
       "AUC ROC              0.766717  0.771612                   0.707799   0.722610   \n",
       "False Positive Rate  0.039431  0.025555                   0.067797   0.018697   \n",
       "False Negative Rate  0.427136  0.431221                   0.516605   0.536082   \n",
       "Accuracy             0.902267  0.920149                   0.807967   0.927106   \n",
       "\n",
       "subpopulation          jewish    muslim     black     white  \\\n",
       "AUC ROC              0.735562  0.715793  0.718407  0.731150   \n",
       "False Positive Rate  0.028875  0.050871  0.092973  0.075077   \n",
       "False Negative Rate  0.500000  0.517544  0.470213  0.462623   \n",
       "Accuracy             0.891414  0.836594  0.779928  0.807198   \n",
       "\n",
       "subpopulation        psychiatric_or_mental_illness  \n",
       "AUC ROC                                   0.792904  \n",
       "False Positive Rate                       0.048338  \n",
       "False Negative Rate                       0.365854  \n",
       "Accuracy                                  0.888620  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results_data['combined']\n",
    "selected_rows = results[results[\"subpopulation\"].isin(identity_columns)]\n",
    "selected_rows.set_index(\"subpopulation\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subpopulation</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC ROC</th>\n",
       "      <td>0.761146</td>\n",
       "      <td>0.762689</td>\n",
       "      <td>0.698295</td>\n",
       "      <td>0.720400</td>\n",
       "      <td>0.748965</td>\n",
       "      <td>0.730675</td>\n",
       "      <td>0.728643</td>\n",
       "      <td>0.739530</td>\n",
       "      <td>0.736410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.041403</td>\n",
       "      <td>0.028420</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.436306</td>\n",
       "      <td>0.446203</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.542105</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.438819</td>\n",
       "      <td>0.446866</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.898198</td>\n",
       "      <td>0.916388</td>\n",
       "      <td>0.812627</td>\n",
       "      <td>0.928337</td>\n",
       "      <td>0.898765</td>\n",
       "      <td>0.836980</td>\n",
       "      <td>0.782546</td>\n",
       "      <td>0.812292</td>\n",
       "      <td>0.878505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subpopulation            male    female  homosexual_gay_or_lesbian  christian  \\\n",
       "AUC ROC              0.761146  0.762689                   0.698295   0.720400   \n",
       "False Positive Rate  0.041403  0.028420                   0.060773   0.017094   \n",
       "False Negative Rate  0.436306  0.446203                   0.542636   0.542105   \n",
       "Accuracy             0.898198  0.916388                   0.812627   0.928337   \n",
       "\n",
       "subpopulation          jewish    muslim     black     white  \\\n",
       "AUC ROC              0.748965  0.730675  0.728643  0.739530   \n",
       "False Positive Rate  0.023810  0.051471  0.103896  0.074074   \n",
       "False Negative Rate  0.478261  0.487179  0.438819  0.446866   \n",
       "Accuracy             0.898765  0.836980  0.782546  0.812292   \n",
       "\n",
       "subpopulation        psychiatric_or_mental_illness  \n",
       "AUC ROC                                   0.736410  \n",
       "False Positive Rate                       0.040000  \n",
       "False Negative Rate                       0.487179  \n",
       "Accuracy                                  0.878505  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results_data['public']\n",
    "selected_rows = results[results[\"subpopulation\"].isin(identity_columns)]\n",
    "selected_rows.set_index(\"subpopulation\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subpopulation</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC ROC</th>\n",
       "      <td>0.772854</td>\n",
       "      <td>0.778424</td>\n",
       "      <td>0.708907</td>\n",
       "      <td>0.727243</td>\n",
       "      <td>0.721381</td>\n",
       "      <td>0.704564</td>\n",
       "      <td>0.710036</td>\n",
       "      <td>0.720894</td>\n",
       "      <td>0.843247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.037332</td>\n",
       "      <td>0.023212</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>0.050331</td>\n",
       "      <td>0.082073</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.416961</td>\n",
       "      <td>0.419940</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.497854</td>\n",
       "      <td>0.479532</td>\n",
       "      <td>0.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.906625</td>\n",
       "      <td>0.923014</td>\n",
       "      <td>0.799180</td>\n",
       "      <td>0.926439</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.838280</td>\n",
       "      <td>0.778736</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.899497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subpopulation            male    female  homosexual_gay_or_lesbian  christian  \\\n",
       "AUC ROC              0.772854  0.778424                   0.708907   0.727243   \n",
       "False Positive Rate  0.037332  0.023212                   0.075145   0.020262   \n",
       "False Negative Rate  0.416961  0.419940                   0.507042   0.525253   \n",
       "Accuracy             0.906625  0.923014                   0.799180   0.926439   \n",
       "\n",
       "subpopulation          jewish    muslim     black     white  \\\n",
       "AUC ROC              0.721381  0.704564  0.710036  0.720894   \n",
       "False Positive Rate  0.034161  0.050331  0.082073  0.078680   \n",
       "False Negative Rate  0.523077  0.540541  0.497854  0.479532   \n",
       "Accuracy             0.883721  0.838280  0.778736  0.800000   \n",
       "\n",
       "subpopulation        psychiatric_or_mental_illness  \n",
       "AUC ROC                                   0.843247  \n",
       "False Positive Rate                       0.057692  \n",
       "False Negative Rate                       0.255814  \n",
       "Accuracy                                  0.899497  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results_data['private']\n",
    "selected_rows = results[results[\"subpopulation\"].isin(identity_columns)]\n",
    "selected_rows.set_index(\"subpopulation\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
